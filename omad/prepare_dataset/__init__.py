"""Prepare Dataset: NPZ dataset preparation"""

from pathlib import Path
import numpy as np

from omad.prepare_dataset.prepare_xy import build_xy, stratified_split_indices, load_anomaly_route_ids

def run_prepare_dataset_batch(
    base_dir: str,
    out_dir: str | None = None,
    percentages: list[str] = None,
    slices: list[int] = None,
    modes: list[str] = None,
    seeds: list[int] = None,
    verbose: bool = False,
):
    """
    Batch mode: Generate all dataset combinations.
    
    Args:
        base_dir: Base directory
        out_dir: Output directory
        percentages: List of percentage strings
        slices: List of T values
        modes: List of anomaly modes
        seeds: List of random seeds
        verbose: Detailed logging
    """
    from omad.utils.logging import console, log_stage_header, create_progress, create_summary_table, log_success
    
    log_stage_header(4, "Dataset Preparation (Batch Mode)")
    
    if percentages is None:
        percentages = ["10pct", "5pct", "3pct", "1pct"]
    if slices is None:
        slices = [12, 24]
    if modes is None:
        modes = ["a1", "a2", "a3"]
    if seeds is None:
        seeds = [2, 12, 22, 32, 42]
    
    base_path = Path(base_dir)
    out_path = Path(out_dir) if out_dir else (base_path / "data")
    out_path.mkdir(parents=True, exist_ok=True)
    
    total_combinations = len(percentages) * len(slices) * len(modes) * len(seeds)
    
    console.print(f"[bold]Generating {total_combinations} dataset combinations[/bold]")
    console.print(f"Output directory: {out_path}\n")
    
    stats = {"total": 0, "success": 0, "skipped": 0, "failed": 0}
    
    with create_progress() as progress:
        task = progress.add_task(
            "[cyan]Processing combinations...",
            total=total_combinations
        )
        
        for pct in percentages:
            for T in slices:
                csv_path = base_path / f"routes_sliced_{T}_injected.csv"
                
                if not csv_path.exists():
                    console.print(f"[yellow]SKIP:[/yellow] {csv_path} not found")
                    stats["skipped"] += len(modes) * len(seeds)
                    progress.update(task, advance=len(modes) * len(seeds))
                    continue
                
                for mode in modes:
                    indices_path = base_path / f"indices/indices_{T}_{mode}.csv"
                    
                    if not indices_path.exists():
                        console.print(f"[yellow]SKIP:[/yellow] {indices_path} not found")
                        stats["skipped"] += len(seeds)
                        progress.update(task, advance=len(seeds))
                        continue
                    
                    # Load data once per (pct, T, mode)
                    anomaly_route_ids = load_anomaly_route_ids(str(indices_path), pct, mode)
                    X_flat, y, route_ids, X_seq = build_xy(
                        str(csv_path), mode=mode, T=T, anomaly_route_ids=anomaly_route_ids
                    )
                    
                    for seed in seeds:
                        try:
                            # Create output directory
                            subdir = out_path / pct / f"slice_{T}_{mode}" / f"seed_{seed}"
                            subdir.mkdir(parents=True, exist_ok=True)
                            
                            # Stratified split
                            tr, va, te = stratified_split_indices(
                                y, train=0.7, valid=0.15, test=0.15, seed=seed
                            )
                            
                            # Save splits
                            for split_name, idx in [("train", tr), ("valid", va), ("test", te)]:
                                np.savez_compressed(
                                    subdir / f"{split_name}.npz",
                                    X=X_flat[idx],
                                    X_seq=X_seq[idx],
                                    y=y[idx],
                                    route_ids=route_ids[idx],
                                )
                            
                            stats["success"] += 1
                            
                        except Exception as e:
                            console.print(f"[red]ERROR:[/red] {pct}/{T}/{mode}/seed_{seed}: {e}")
                            stats["failed"] += 1
                        
                        finally:
                            stats["total"] += 1
                            progress.update(task, advance=1)
    
    # Display summary
    summary = create_summary_table("Prepare Dataset Summary", stats, title_style="bold green")
    console.print("\n")
    console.print(summary)
    console.print(f"\nâœ“ Datasets saved to: {out_path}\n")
    log_success("Prepare Dataset completed successfully")


def run_prepare_dataset_single(
    csv: str,
    mode: str,
    T: int,
    percentage: str,
    seed: int,
    output_dir: str,
    prefix: str | None = None,
    train: float = 0.7,
    valid: float = 0.15,
    test: float = 0.15,
    verbose: bool = False,
):
    """
    Single mode: Generate one dataset configuration.
    
    Args:
        csv: Input CSV path
        mode: Anomaly mode (a1/a2/a3)
        T: Time slice length
        percentage: Anomaly percentage
        seed: Random seed
        output_dir: Output directory
        prefix: File prefix
        train: Train ratio
        valid: Valid ratio
        test: Test ratio
        verbose: Detailed logging
    """
    from omad.utils.logging import console, log_stage_header, log_success
    
    log_stage_header(4, "Dataset Preparation (Single Mode)")
    
    # Implementation similar to batch but for single config
    console.print(f"Generating dataset: {percentage}/{T}/{mode}/seed_{seed}")
    
    # Load indices and build dataset
    # ... implementation ...
    
    log_success("Prepare Dataset completed successfully")


# Aliases for backward compatibility
run_stage4_batch = run_prepare_dataset_batch
run_stage4_single = run_prepare_dataset_single
